# SPDX-FileCopyrightText: 2022 Renaissance Computing Institute. All rights reserved.
# SPDX-FileCopyrightText: 2023 Renaissance Computing Institute. All rights reserved.
# SPDX-FileCopyrightText: 2024 Renaissance Computing Institute. All rights reserved.
#
# SPDX-License-Identifier: GPL-3.0-or-later
# SPDX-License-Identifier: LicenseRef-RENCI
# SPDX-License-Identifier: MIT

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: "{{- include "apsviz-timeseries-postgres.fullname" . }}-scripts"
data:
  init-apsviz.sh: |-
    #!/bin/sh
    set -e

    # Check to see if the apsviz_gauge DB and user exist. if not create them
    psql -v ON_ERROR_STOP=1 --username "{{ .Values.adminUser }}" <<-EOSQL
            CREATE DATABASE "{{ .Values.timeseriesDBName }}" WITH OWNER = postgres TABLESPACE = pg_default CONNECTION LIMIT = -1 IS_TEMPLATE = False;
            CREATE ROLE "{{ .Values.timeseriesUserName }}" WITH LOGIN NOSUPERUSER NOCREATEDB NOCREATEROLE INHERIT NOREPLICATION CONNECTION LIMIT -1 PASSWORD '{{ .Values.timeseriesUserPW }}';
            CREATE ROLE "{{ .Values.timeseriesDBName }}"  WITH LOGIN SUPERUSER NOCREATEDB NOCREATEROLE INHERIT NOREPLICATION CONNECTION LIMIT -1 PASSWORD '{{ .Values.timeseriesUserPW }}';
            GRANT ALL PRIVILEGES ON DATABASE "{{ .Values.timeseriesDBName }}" TO "{{ .Values.timeseriesUserName }}";
            GRANT ALL PRIVILEGES ON DATABASE "{{ .Values.timeseriesDBName }}" TO "{{ .Values.timeseriesDBName }}";
            GRANT ALL PRIVILEGES ON DATABASE "public" TO "{{ .Values.timeseriesUserName }}";
            GRANT ALL PRIVILEGES ON DATABASE "public" TO "{{ .Values.timeseriesDBName }}";
    EOSQL
    
  create-extensions.sh: |-
    #!/bin/sh
    set -e

    # Add PostGIS and TimescaleDB extensions to apsviz_gauges DB
    psql -v ON_ERROR_STOP=1 -d "{{ .Values.timeseriesDBName }}" --username "{{ .Values.adminUser }}" <<-EOSQL
            CREATE EXTENSION IF NOT EXISTS postgis CASCADE;
            CREATE EXTENSION IF NOT EXISTS postgis_topology CASCADE;
    EOSQL

  install-crosstab.sh : |-
    #!/bin/sh
    set -e

    # run the install for the crosstab func
    psql -v ON_ERROR_STOP=1 -d "apsviz_gauges" --username "{{ .Values.adminUser }}" <<-EOSQL
            CREATE EXTENSION tablefunc;
    EOSQL

  install-renci-funcs.sh : |-
    #!/bin/sh
    set -e

    # run the create script for obs/mod data
    psql -v ON_ERROR_STOP=1 -d "apsviz_gauges" --username "{{ .Values.adminUser }}" -f /docker-entrypoint-initdb.d/get-obs-timeseries-station-data.sql

    # run the create script for forcast data
    psql -v ON_ERROR_STOP=1 -d "apsviz_gauges" --username "{{ .Values.adminUser }}" -f /docker-entrypoint-initdb.d/get-forecast-timeseries-station-data.sql

  get-obs-timeseries-station-data.sql : |-
    create function get_obs_timeseries_station_data(_station_name character varying, _start_date character varying, _end_date character varying, _nowcast_source character varying) returns json
        language plpgsql
    as
    $$
       DECLARE _output json;
       DECLARE pivot_sql text =
           'SELECT JSON_AGG(ct)
            FROM (SELECT *
               FROM CROSSTAB
                   (
                    ''SELECT
                        CAST(d.time AS TEXT) AS id,
                        s.data_source AS category,
                        COALESCE(d.water_level,
                        d.stream_elevation,
                        d.wave_height,
                        d.wind_speed,
                        d.air_pressure,
                        d.flow_volume) AS yaxis
                    FROM
                       drf_gauge_data d
                    JOIN
                       drf_gauge_source s ON s.source_id=d.source_id
                    JOIN
                       drf_gauge_station g ON s.station_id=g.station_id
                    WHERE
                       g.station_name= ''''' || _station_name || ''''' AND
                       time >= ''''' || _start_date || ''''' AND time <= ''''' || _end_date || '''''
                    ORDER BY d.time'',
                    ''SELECT data_source FROM (VALUES (''''air_barometer''''),
                                                      (''''' || _nowcast_source || '''''),
                                                      (''''ocean_buoy''''),
                                                      (''''tidal_gauge''''),
                                                      (''''tidal_predictions''''),
                                                      (''''coastal_gauge''''),
                                                      (''''river_gauge''''),
                                                      (''''stream_gauge''''),
                                                      (''''wind_anemometer'''')) b(data_source)''
                    ) AS (
                     time_stamp TEXT,
                     "air_barometer" double precision,
                     ' || SPLIT_PART(_nowcast_source::TEXT, '.', 1) || SPLIT_PART(_nowcast_source::TEXT, '.', 2) || ' double precision,
                     "ocean_buoy_wave_height" double precision,
                     "tidal_gauge_water_level" double precision,
                     "tidal_predictions" double precision,
                     "coastal_gauge_water_level" double precision,
                     "river_gauge_water_level" double precision,
                     "stream_gauge_stream_elevation" double precision,
                     "wind_anemometer" double precision
                    )) AS ct';
    BEGIN
        -- gather the records and return them in json format
            EXECUTE (select pivot_sql) INTO _output;

        -- return the data to the caller
        return _output;
    END
    $$;
    alter function get_obs_timeseries_station_data(varchar, varchar, varchar, varchar) owner to postgres;
    grant execute on function get_obs_timeseries_station_data(varchar, varchar, varchar, varchar) to apsviz_ingester;


  get-forecast-timeseries-station-data.sql : |-
    CREATE OR REPLACE FUNCTION  get_forecast_timeseries_station_data(_station_name character varying, _timemark character varying, _data_source character varying)
      RETURNS json
      LANGUAGE plpgsql
    AS $function$
       DECLARE
           _output json;
       DECLARE pivot_sql text =
           'SELECT JSON_AGG(ct)
            FROM (SELECT *
               FROM CROSSTAB
                   (
                    ''SELECT
                        CAST(d.time AS TEXT) AS id,
                        s.data_source AS category,
                        coalesce(d.water_level) AS axis
                    FROM
                       drf_gauge_data d
                    JOIN
                       drf_gauge_source s ON s.source_id=d.source_id
                    JOIN
                       drf_gauge_station g ON s.station_id=g.station_id
                    WHERE
                       g.station_name = ''''' || _station_name || ''''' AND
                       timemark = ''''' || _timemark || ''''' AND data_source = ''''' || _data_source || '''''
                    ORDER BY d.time''
                    ) AS (
                     time_stamp TEXT,
                     ' || SPLIT_PART(_data_source::TEXT, '.', 1) || SPLIT_PART(_data_source::TEXT, '.', 2) || ' double precision
                    )) AS ct';
    BEGIN
        -- gather the records and return them in json format
            EXECUTE (select pivot_sql) INTO _output;

        -- return the data to the caller
        return _output;
    END
    $function$;
    ALTER FUNCTION public.get_forecast_timeseries_station_data(character varying, character varying, character varying) OWNER TO postgres;
    GRANT EXECUTE ON FUNCTION public.get_forecast_timeseries_station_data(character varying, character varying, character varying) TO apsviz_ingester;

  loaddb.sh: |-
    #!/bin/bash
    apt-get -yq update
    apt-get -yq install zip

    BASE_DIR=/data
    DUMPS_DIR=$BASE_DIR/db-backups

    BCKP_FILE_1=$DUMPS_DIR/{{ .Values.sqlFile1 }}
    BCKP_FILE_2=$DUMPS_DIR/{{ .Values.sqlFile2 }}

    until pg_isready ; do
        echo "postgres not ready";
        sleep 10
    done

    # restore the roles without the postgres password. psql us used here because it is in text format
    psql -U {{ .Values.adminUser }} < $BCKP_FILE_1

    # restore the databases. pg_restore is used here because it is a compressed backup
    pg_restore -d postgres --clean --create $BCKP_FILE_2

    # this is truly a hack. pg_restore returns a count of warnings,
    # in this case a warning stating that the "public schema already exists".
    # this ends up creating issues in k8s. note in this case the public schema
    # existing is due to the base postgres image used for postgis.
    exit 0

  dumpDatabase.sh: |-
    #
    # backs up certain important databases.
    #
    # should be run as a cronjob nightly at midnight (local), e.g.
    # 0 21 * * * postgres /storage/backups.sh
    BASE_DIR=/data
    DUMPS_DIR=$BASE_DIR/db-backups

    if [ -e $LOG_PATH/export.log ]; then
        rm $LOG_PATH/export.log
    fi

    date >> $LOG_PATH/export.log

    # increment the dump file version numbers
    for i in `psql -h $DB_HOST -c "SELECT datname FROM pg_database where datname in ('apsviz_gauges')" | head -n -2 | tail -n +3`; do
        for j in {8..1}; do
            DUMP_FILE=$DUMPS_DIR/$i.dump.$j
            NEW_DUMP_FILE=$DUMPS_DIR/$i.dump.$(( j + 1 ))

            # rename the dump file version
            if [ -e $DUMP_FILE ]; then
                echo "mv $DUMP_FILE $NEW_DUMP_FILE" >> $LOG_PATH/export.log
                mv $DUMP_FILE $NEW_DUMP_FILE
            fi
        done
    done

    # perform the dumps
    for i in `psql -h $DB_HOST -c "SELECT datname FROM pg_database where datname in ('apsviz_gauges')" | head -n -2 | tail -n +3`; do
        # remove the last globals file version if it exists
        if [ -e $DUMPS_DIR/$i.dump.8 ]; then
            echo "removing $DUMPS_DIR/$i.dump.8" >> $LOG_PATH/export.log
            rm $DUMPS_DIR/$i.dump.8
        fi

        # get the dump
        echo "dumping...$DUMPS_DIR/$i.dump.1" >> $LOG_PATH/export.log
        date >> $LOG_PATH/export.log
        pg_dump -h $DB_HOST -d $i -Fc -f $DUMPS_DIR/$i.dump.1
        date >> $LOG_PATH/export.log
    done

    # increment the globals file version numbers
    for j in {8..1}; do
      GLOBALS_FILE=$DUMPS_DIR/ts_dbglobals.sql.$j
      NEW_GLOBALS_FILE=$DUMPS_DIR/ts_dbglobals.sql.$(( j + 1 ))

      # rename the globals file version
      if [ -e $GLOBALS_FILE ]; then
          echo "mv $GLOBALS_FILE $NEW_GLOBALS_FILE" >> $LOG_PATH/export.log
          mv $GLOBALS_FILE $NEW_GLOBALS_FILE
      fi
    done

    # remove the last globals file version if it exists
    if [ -e $DUMPS_DIR/ts_dbglobals.sql.8 ]; then
      echo "removing $DUMPS_DIR/ts_dbglobals.sql.8" >> $LOG_PATH/export.log
      rm $DUMPS_DIR/ts_dbglobals.sql.8
    fi

    # get the globals file
    echo "dumping...$DUMPS_DIR/ts_dbglobals.sql.1" >> $LOG_PATH/export.log
    date >> $LOG_PATH/export.log
    pg_dumpall -h $DB_HOST --globals-only | grep -v 'ROLE postgres' > $DUMPS_DIR/ts_dbglobals.sql.1
    date >> $LOG_PATH/export.log

    exit 0
